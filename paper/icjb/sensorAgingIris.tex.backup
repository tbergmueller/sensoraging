\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{ijcb}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{cite}
\usepackage{algpseudocode}

\usepackage{url}
\urldef{\mailsa}\path|thomas.bergmueller@authenticvision.com| 
\urldef{\mailsb}\path|uhl@cosy.sbg.ac.at|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}



\providecommand{\myceil}[1]{\left \lceil #1 \right \rceil }
\providecommand{\myfloor}[1]{\left \lfloor #1 \right \rfloor }







% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
%\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%\ijcbfinalcopy % *** Uncomment this line for the final submission

\def\ijcbPaperID{****} % *** Enter the IJCB Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifijcbfinal\pagestyle{empty}\fi
\begin{document}

%%%%%%%%% TITLE
\title{Impact of sensor aging on iris recognition}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   Similar to the impact of aging on human beings, digital image sensors develop aging effects over time. Since these imager's aging effects (commonly denoted as pixel defects) leave marks in the captured images, it is not clear whether this affects the accuracy of iris recognition algorithms. This paper proposes a method to investigate the influence of sensor aging on iris recognition by simulative aging of an iris test database. A pixel model is introduced and an aging algorithm is discussed to create a test database. To establish practical relevance, the simulation parameters are obtained from the observed 4-year-aging effects of a real iris scanner.
\end{abstract}

%%%%%%%%% BODY TEXT



\section{Introduction}
% TODO probably start with a quote
The aging process starts immediately after being given birth. At first, aging's aspects are considered to be rather positive. One grows up, gets stronger and learns new things. At a certain point, aging starts to reveal several drawbacks. The skin gets wrinkled, joints and bones start to ache and also our vision starts to degenerate. In either case, aging changes parts of our body. Although human beings change, others are still able to recognize people they knew before, even when they haven't met in a long time and therefore aging changed their appearance significantly.
Biometric systems aim to identify human beings by analysing their biometric samples, i.e. the face, the fingerprints or iris \cite{rathgeb}. These systems operate in two steps. In the enrollment process, a subject's biometric samples are registered for the first time and stored in a database. Later, in the authentication procedure, another sample of a subject's biometric samples is taken and compared to the one stored in the database to verify the subject's identity. \\
Since there may be years or decades between the enrollment and the authentication, one strives to use biometric samples which are stable over time. The iris has widely been assumed to be stable, although it is currently topic of intensive discussion if and which iris-related information eventually changes in a human's aging process. Some researchers claim that iris-related information is stable or relatively stable \cite{daugmanPatent, daugmanNoChange, grotherStability, monroDCTIris}, while others observe significant changes over time \cite{rankinChange, rankinChangeResponse, fenkerIrisAging, czajkaTemplateAging, fairhurstNonstability}. Researchers mostly conclude these age-dependent changes in iris texture by observing changes in a system's iris-recognition rate. It is not clear, if observed changes in an algorithms' behaviour are caused by the aging of the tested subject, which is commonly assumed, aging of the recognition system itself or if this is caused by other unspecified factors.

This paper proposes a method to investitage the influence of aging effects of digital image sensors, which are crucial components of the recognition system. As a human being's vision often gets weaker with age, pixels start to get defective in image sensors over the years as well. This influences the quality - and therefore the appearance - of the captured images. Similar to being able to estimate a human being's age by his appearance, pixel defects observed in the captured images can reveal the age of the corresponding imager. This is used in image forensics to approximate the capturing date of an image \cite{fridrich}. However, since the aging effects of the sensor can be traced by evaluation of its output, namely the images, this implies that the capturing process is not time invariant. Hence two images, which capture the same (unchanged) scene, but were taken at significantly different points in time, may differ due to developed sensor defects in the meantime.

% TODO rephrase
There might arise problems due to sensor aging, because iris recognition systems operate by comparing current samples to earlier taken ones stored in a database. Special cameras with digital image sensors are commonly used to capture the iris features in both cases, the enrollment and the authentication process. It is not clear yet, whether the aging of the sensor - and thus the development of aging effects between taking two samples - influence the accuracy of iris recognition algorithms. To investigate this issue, one would need to have identical data captured at at least two significantly different points in time. It is practically impossible to establish identical conditions for both shots. Furthermore, as mentioned, it is not possible to distinguish between the influence of the subject's and the sensor's aging on iris recognition algorithms. For this reason one cannot capture test data to investigate the sensor's or the subject's aging in an isolated manner physically. There is no way to explicitely examine the iris texture's aging at all. However, it is possible to investigate the sensor aging's influence on the iris recognition rate independent from the subject's aging.

%TODO Check Notredame for one sensor only
\textit{
We proposes a method to investigate the influence of a sensor's aging on the recognition rate. This is done by generating test data based on an the IITD iris database \cite{iitd} (TODO: Check if all captured by one sensor) by a simulated aging process. The practical relevance of this simulation is ensured by retrieving the simulation parameters from two iris databases 'NAME' \cite{agedIris}, where the same subjects were captured by the same sensor in 2009 and 2013. A method to retrieve the simulation parameters from this data is introduced in section \ref{hotPixelRate}. Using these simulation parameters, a pixel model and method to age images by generating images with hot and stuck pixels is discussed in \ref{virtualAging}. This test database is then used to test six implementations of iris recognition algorithms available in the University of Salzburg Iris Toolkit (USIT) \cite{usit} for influence of sensor aging effects upon the equal error rate (EER), refer section \ref{testing}. Finally we discuss the results and limitations of our tests (see section \ref{results}) and interpret them to give a statement about the influence of sensor aging on iris recognition algorithms in section \ref{conclusion}.}


\section{Sensor aging and pixel model}
\label{sec:agingAndPixelModel}
An image sensor is a two dimensional array of photosensitive cells called pixels. The purpose of an image sensor is to convert the incoming light to its digital representation, which is commonly denoted as the image \cite{imageSensors}. In theory, each of these pixels has the same rectangular shape and a unified photo-response, meaning all pixels should produce the same output value on unified incoming light. Due to imperfections in the manufacturing process, this is not the case in practice, hence there are pixels which are more sensitive than others \cite{camAndDisplays}. Besides that, some of a sensor's pixels might change their initial photo-response characteristic over the lifetime of a sensor. We denote this defect-development over time as \emph{sensor aging}.
Related work shows that such pixel defects caused by aging are equally distributed and independent throughout the sensor. Furthermore, it is well known that the development of pixel defects linked to material-related faults is an increasing function of time \cite{datingImages, inFieldDefects, defectDetection,failureSemi, defectIdentification, fridrich}.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/defects.png}
\caption{A \emph{partially-stuck or hot pixel} (1) and two \emph{stuck pixels} (2) in an iris image. Contrast has been enhanced in the close-ups for visualisation. Note that the partially-stuck pixel still corresponds to the incoming light, but is significantly brighter compared to its neighbours, while the stuck pixel are light-independent and yield to a constant output.  }
\label{fig:hotStuck}
\end{figure}

The most common defects occuring over time are partially and fully stuck pixels, illustrated in fig. \ref{fig:hotStuck}. Partially-stuck pixels tend to have a moderate offset compared to their neighbours, but still respond to the incident light. Stuck pixels produce a completely light-independent output value and are often (but necessarily) saturated \cite{fridrich}. As soon as a pixel is defective, it remains defective over the rest of the sensor's lifetime \cite{failureSemi}, regardless which type of defect it suffers from. So one can obtain the important property that if a pixel is \emph{once defective, it remains defective}. This is shown in fig. \ref{fig:defectLocations}.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{img/defectLocations.png}
\caption{Illustration of uniformly distributed and independent locations of partially-stuck (circle) and stuck (filled circle) pixels in images taken at 3 significantly different points in time T1, T2, T3.}
\label{fig:defectLocations}
\end{figure}

The occurrence of new pixel defects can be modelled by a poisson process, because the number of pixel defects is increasing with time and defect locations are uniformly distributed and independent. Already known defects remain constant in respect to their location and type \cite{fridrich, defectIdentification}. 
To run a simulation, a model for calculating the pixel values of an image $y$ has to be defined. There are several pixel output models around, which consider the incoming light and the impact of pixel defects on the raw output of a sensor. We denote $w,h \in \mathbb{Z}$ as the rows and columns of the sensor and start by adopting the model proposed in \cite{fridrich}:

\begin{equation}
\begin{aligned}
 Y = I+I \circ K+\tau D +c+\Theta \\ with \quad Y,I,K,D,C, \Theta \in \mathbb{R}^{w \times h}; \tau \in \mathbb{R}
\end{aligned}
  \label{equ:pixelmodel}
 \end{equation}

where $Y$ is the sensor output, commonly denoted as image, $I$ the intensity of incoming light, $I \circ K$ the photo-response non-uniformity PRNU, $\tau D$ the dark current (with $\tau$ being a multiplicative-factor representing exposure settings, sensor temperature, \dots), $C$ a light-independent offset and $\Theta$ some modeling noise. Since all pixels are independent \cite{fridrich, defectDetection} and all operations element-wise, we denote the matrix-elements $y_{x,y} \in Y$ as $ y \in Y$ for simplicity reasons. The same applies to $i \in I$, $k \in K$, $d \in D$, $c \in C$ and $\theta \in \Theta$.\\
Since we're interested in simulating the aging effects of a specific sensor, all age-independent defects, which are e.g. due to production process, can be eliminated. Hence the PRNU, which corresponds to the non-uniformity of pixel-dimensions, can be omitted. As we're interested in reproducable tests, this means environmental influence (e.g. temperature) and modelling noise should be minimized. They can be eliminated completely in a simulation, thus we set $k=\theta=0$. Also the same exposure settings have to be used for the sensor in every test, therefore we have $\tau = const$ and set $ \tau = 1$ for simplicity. \cite{camAndDisplays, radiometricCCD,failureSemi,fridrich} suggest that the dark current is very weak with short exposure, which is necessary for applications in biometric systems to avoid motion blur. Under these considerations, a fairly simple model, considering only aging-relevant defects, remains:

\begin{equation}
  \label{equ:pixemodelEasier}
  y = i + d + c \quad with \quad y,i,c \in \mathbb{R}
\end{equation}

Common defect types that develop over time as the sensor ages are stuck and hot pixels, where the definitions are quite contrary in literature (e.g. in \cite{fridrich, defectIdentification, failureSemi}). If the dark current $d$ of a pixel is extremely high, this is often denoted as a hot pixel. If the offset $c$ is high, this results in a saturated pixel and is called a stuck pixel according to \cite{fridrich}. \cite{defectIdentification}, however, suggests that a stuck pixel is not necessarily saturated but can obtain any value within the sensor output's universe. For the reason of non-uniform definitions we define the following models for defective pixels:

\begin{eqnarray}
  y & = & c \label{equ:Stuck} \\
  y & = & i + d \label{equ:Hot}
\end{eqnarray}
  
where the defect type in equ. \ref{equ:Stuck} is light-independent (thus referred as a \emph{stuck pixel}) and the one in equ. \ref{equ:Hot} adds an offset to the incident light and is commonly referred as either a partially-stuck or hot pixel. The dark current (which is the cause for hot pixels) depends on exposure time and temperature, which are both kept constant this experiment. Thus also the dark current is constant and therefore there is no difference between a hot and a partially stuck pixel for this setup. We will denote this effect as a \emph{partially-stuck pixel}. In conclusion (and considering 8 bit grayscale images), the following pixel model is definied:

\begin{equation}
\begin{aligned}
Y_{x,y} = \begin{cases}
C_{x,y}  & \text{if $c_{x,y} \neq 0$}; \\
I_{x,y} +D_{x,y}  & \text{otherwise}.\\
\end{cases} \\ \text{with} \quad Y,C,I,D \in {(\mathbb{Z}:[0;255])}^{w \times h}
\label{equ:finalPixelModel}
\end{aligned} 
\end{equation}

where $Y_{x,y}$-values are clipped at $0$ and $255$ respectively if interval borders are exceeded. This means they are able to saturate. 

\section{Simulated sensor aging}
\label{virtualAging}
For an ideal sensor, the defect matrices $C$ and $D$ are zero matrices at a specific point in time $T_0$. As pixel defects occur at a constant rate, this can be modelled by a poisson process \cite{fridrich}. Hence the number of stuck pixels and partially stuck pixels, denoted as $n_{s}$ and $n_{ps}$ respectively, at $T_i$ can be calculated as

\begin{eqnarray}
   n_s(t)  & = & (T_i-T_0) \lambda_s \\
  n_{ps}(t) & = &  (T_i-T_0) \lambda_{ps}
\end{eqnarray}

where $\lambda_s$ and $\lambda_{ps}$ are the rates at which the particular defect types occur. Due to defects being independent of each other, the locations of the defects among a 2D sensor array can be modelled by a uniform distribution. Thus the defect location $(x,y)$ can be obtained using random numbers $r$. We propose the following procedure to obtain the position $s_k \in {w \times h}$ of the $k$-th pixel defect:

\begin{equation}
 s_k(x,y) = (\myfloor{\frac{r}{w}}, r \mod{w})) \quad \text{with} \quad r \in [0:w \cdot h]
 \label{equ:defectLocation}
\end{equation}

Depending on the $k$-th defect being a stuck or partially stuck pixel, the values of $C$ and $D$ according to the model defined in equ. \ref{equ:finalPixelModel} have to be set. We denote $a_s$ as the maximum amplitude of a stuck pixel and $a_{ps}$ the maximum amplitude of a partially stuck pixel. Let $r_a \in \mathbb{R}:[0;1]$ be a uniformly distributed random number. Then we either have

\begin{eqnarray}
   C_{s_k}  & = & r_a \cdot a_s \quad \text{for stuck pixel at } s_k \text{ or} \label{equ:stucks} \\
   D_{s_k} & = &  r_a \cdot a_{ps} \quad \text{for partially stuck pixel at } s_k \label{equ:partiallyStuck}
\end{eqnarray}

These definitions together with the pixel model introduced in equ. \ref{equ:finalPixelModel} can be used to simulatively add aging-related sensor defects to an existing image $Y_{T_0}$ captured at time ${T_0}$. One might argue that $Y_{T_0}$ already contains pixel defects since the used sensor might bear defects at $T_0$ already. Since we are only interested in investigating if something changes over a period of time, it does not matter which time frame we observe. This means, already contained defects in $Y_{T_0}$ do not influence the outcome of the experiment. \\
Using the pixel model, sensor defects corresponding to a sensor's physical status at a specific time $T_i$ can be embedded in the image $Y_{T_0}$. The resulting image $Y_{T_i}$, denoted as \emph{aged image}, can be interpreted as an image capturing the completely same scene as in $T_0$, but revealing the effects of sensor aging over a period of time $\Delta t = {T_i} - {T_0}$. Because sensor defects change over time, we define a sequence of defect matrices, which represent the state of aging at a specific point in time $T_i$. We denote these sequences corresponding to sample points $T_0$ \dots $T_m$ as

\begin{equation}
\begin{aligned}
(D_i)_{i=0..m} \text{ and } (C_i)_{i=0..m} \\ 
\text{with} \quad C_i, D_i \in {(\mathbb{Z}:[0;255])}^{w \times h}
\end{aligned}
\end{equation}

With these definitions the influence of the physical state of the sensor at a considered sample point $T_i$ can be embedded in an image simulatively. The following algorithm is proposed to compute the sequence of aged images $Y_{T_1} \dots Y_{T_m}$ from a source image $Y_{T_0}$:

\vspace{5mm}
\begin{algorithmic}[1]

\Procedure{AgedImageSequence}{$Y_{T_0}$}

\For{$i=1 \dots m$}
\State $\Delta n_s\gets n_s(T_i - T_0) - n_s(T_{i-1} - T_0) $ 
\State $\Delta n_{ps}\gets n_{ps}(T_i - T_0) - n_{ps}(T_{i-1} - T_0) $
\State $D_i$ = $D_{i-1}$
\State $C_i$ = $C_{i-1}$

  \For{$k=1 \dots \Delta n_s$}
    \State $r_a \gets$ random in $[0;1]$
    \State $s_k \gets$ random in $w \times h$ (equ. \ref{equ:defectLocation})
    \State $C_{s_k} \gets r_a \cdot a_s$ (equ. \ref{equ:stucks})
  \EndFor
  
  \For{$k=1 \dots \Delta n_{ps}$}
    \State $r_a \gets$ random in $[0;1]$ 
    \State $s_k \gets$ random in $w \times h$ (equ. \ref{equ:defectLocation})
    \State $D_{s_k} \gets r_a \cdot a_{ps}$ (equ. \ref{equ:partiallyStuck})
  \EndFor
  
  
  $Y_{T_{i_{x,y}}} = \begin{cases}
  C_{i_{x,y}}  & \text{if $C_{i_{x,y}} \neq 0$}; \\
  Y_{T_{0_{x,y}}} +D_{i_{x,y}}  & \text{otherwise}.
  \end{cases}$
  
\EndFor
\State \textbf{return} $(Y_{T_i})_{i=1 \dots m}$
\EndProcedure
\end{algorithmic}

\vspace{5mm}


Basically for each point in time the number of defects-to-add $\Delta n_s, \Delta n_{ps}$ are calculated. The defect matrices $D$ and $C$ are computed recursively. This is necessary to satisfy the \emph{once defective, always defective} condition. By recursive calculation the earlier developed defects are maintained over virtual age. As soon as the defects for the $i$-th aging step are defined, they are used to compute an aged image $Y_{T_i}$ using the pixel model defined in equ. \ref{equ:finalPixelModel}. Instead of the incident light $I$, the base image $Y_{T_0}$ can be used due to the previously given arguments. At the end we obtain a sequence  $(Y_{T_i})_{i=1 \dots m}$ Each pixel sequence $y_i$ represents completely the same incident light as in $Y_{T_0}$ but also bears the information of the age-dependent defects of a sensor for a specific point in time $T_i$.
%TODO: Rephrase this last sentence...
 
 \subsection{Parameter retrieval from iris databases}
 \label{hotPixelRate}
 For the discussed simulative aging process, the defect's growth rate and amplitudes have to be defined. In laboratory set-ups hot and \emph{partially stuck pixels} are usually identified by dark calibration tests (i.e. $I=0$) \cite{defectIdentification}. To the best of the authors' knowledge, there is no suitable laboratory-captured data set available for iris imagers. There are databases \cite{czajkaTemplateAging, agedIris} available, which were captured using the same equipment at two significantly capturing dates for the purpose of investigating iris texture aging. In the following we propose a method to retrieve the growth rate and amplitudes of partially and fully stuck pixels from such databases.\\

For the pixel model defined in equ. \ref{equ:finalPixelModel}, the growth rate and amplitudes of partially and fully stuck pixels have to be detected. As discussed, this type of defect is usually detected from a single image when the incident light I is simply set to an uniform and known value, i.e. $I=0$. Hence only the defects $\Xi = D+C = Y-I$ remain. Because in our database $I$ is unknown, a statistical approach has to be used.
We denote $Y_0 \dots Y_K$ a sequence of $K$ images taken in a very short period of time. We know that a sensor defect has to be contained in each of this image and is (according to equ. \ref{equ:finalPixelModel}) independent of $I$. A \emph{stuck pixel} obtains the same value in each image in this sequence. Hence a pixel $y \in Y$ at position $(x,y)$ is identified as being stuck iff

\begin{equation}
y_{0} = y_{1} = \dots = y_{K} \label{equ:conditionStuck}
\end{equation}

To additionally find partially stuck pixels, we compute a pixel's mean $\bar{y}$ from the sequence of images:
\begin{eqnarray}
\bar{y} & = & \frac{1}{K}\sum\limits_{k=1}^{K}y_k \\
\bar{y} & = & \frac{1}{K}\sum\limits_{k=1}^{K}(y_k+d+\theta_k) \label{equ:modelWithNoise} \\
\bar{y} & = & d+\frac{1}{K}\sum\limits_{k=1}^{K}(y_k) \label{equ:modelWithD}
\end{eqnarray}

Equ. \ref{equ:modelWithNoise} is obtained by using the pixel model of equ. \ref{equ:finalPixelModel} (without $c$, because stuck pixels fulfilling equ. \ref{equ:conditionStuck} are ruled out already) and adding some modelling noise $\theta$. Since $d$ is a defect and therefore contained in every one of the sequences images, it is independent of k. The mean of a uniformly distributed modelling noise $\theta$ cancels out for sufficiently large K. So we get equ. \ref{equ:modelWithD}.

The mean $\bar{y}$ at a certain location has the same value as if taken the median over several $\bar{y}_i$ in its local neighbourhood with distance $q$. This holds if the neighbouring pixels $\bar{Y}_{{x \pm q, y \pm q}}$ had similar pixel values in the original images $Y_i$. Therefore we have the identity $med(y,q) = \bar{y}$, even if one (but less than half) of the $\bar{y}i$ in the neighbourhood is significantly different. Hence sparse pixel defects, which contribute to the mean, disappear when applying median filtering on the mean image's pixels $\bar{y}$ in a local neighbourhood. Considering only parts of the mean image $\bar{Y}$, where mostly unified brightness and texture is present in $Y_1 \dots Y_K$ we compute the estimator $\hat{d}$ for $d$ as

\begin{eqnarray}
med(\bar{y},q) = \hat{d}+\frac{1}{K}\sum\limits_{k=1}^{K}(y_k) \\
\hat{d} = \frac{1}{K}\sum\limits_{k=1}^{K}y_k - med(\bar{y},q) \label{equ:d}
\end{eqnarray}


\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/correlated.png}
  \caption{The mean image of $Y_1 \dots Y_k$ (left) has correlated data in the image's centre because of the iris usually being there. This (marked) region is not considered when detecting sensor defects. The histogram (right) of the uncorrelated regions is indeed similar to uniform distribution}
  \label{fig:correlated}
\end{figure}

Amongst the partially stuck pixel information, also information about the PNRU is also contained in $\hat{D}$. Since PNRU is caused by imperfections in the manufacturing process, it is likely to be normally distributed which reflects in the logarithmic histogram of $\hat{D}$, as shown in fig. \ref{fig:defectMat}. The size $q$ has to be chosen large enough to minimize the influence of PNRU on the median $med(\bar{y},q)$, which is the case if a normal distribution within the neighbourhood is observed.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{img/defectMatWithTau.png}
  \caption{Matrix D (left, enhanced for visualisation) is calculated by equ. \ref{equ:d}. The logarithmic histogram (right) of the uncorrelated regions shows a normal distribution, which is due to PNRU. The decision threshold $\tau_{ps}$ is so that only outliers are declared as partially stuck pixels}
  \label{fig:defectMat}
\end{figure}


We declare a pixel to be partially stuck if $\hat{d}$ is an outlier and therefore higher sensivitiy is unlikely to correspond to PNRU. This is decied by checking for a certain threshold $\hat{d} > \tau_{ps}$. The decision threshold is chosen, i.e. manually, to just get approximately same amount of outliers in $T_1$ and $T_2$. We exploit the \emph{once defective, always defective}-property to guarantee correct results, even if $\tau_{ps}$ has been slightly off. We know that a sensor's partially stuck pixels from $T_1$ also have to be present in $T_2$. This is illustrated in fig. \ref{fig:defectPersistence}. The number of defects $n_{match}$, which are present at the same location $s_k$ in the images captured at $T_1$ and $T_2$ can be determined. Considering the number of defects $n_1$ in the image captured at $T_1$, the correction factor $\gamma$ of the algorithm can be calculated as
\begin{equation}
\gamma = \frac{n_{match}}{n_1}
\end{equation}

Assuming that for $T_1$ and $T_2$ the same error is made, the observed increase of defects can be corrected with $\gamma$. Taking into account the size of the sensor $w\cdot h$, we retrieve the simulation parameters by the following relations: 

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{img/detectedLocations.png}
  \caption{Locations of partially-stuck pixel candidates. Correctly classified pixel defects from $T_1$ are contained in $T_2$ as well. All other detected defects in $T_1$ can be interpreted as misclassification, since they violate the \emph{once defective, always defective}-condition.}
  \label{fig:defectPersistence}
\end{figure}


\begin{eqnarray}
 \lambda_{ps} 	& = 	& \gamma \frac{n_2-n_1}{(T_2-T_1)\cdot(w \cdot h)} \\ 
 \lambda_{s} 	& = 	& \gamma  \frac{n_{s2}-n_{s1}}{(T_2-T_1)\cdot(w \cdot h)} \\
 a_{ps} 	& = 	&max(\hat{D}_{s_k}) \\ 
 a_{s} 		&:= 	& 255
\end{eqnarray}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental setup}
 \label{testing}
 The proposed method is used to retrieve simulation parameters from two databases, which cover the same test subjects and were captured using the same sensor in 2009 and 2013.

TODO Luca:
\begin{itemize}
 \item I'd call this paragraph 'Relevance of the used database'
 \item Introduce database (``release note'')
 \item Argue relevance of data base (one sensor only) ... 
 \item Mention methods of prove why they are really from the same sensor (pls use BibTex-References)
\end{itemize}

We used the proposed method in section \ref{hotPixelRate} to retrieve the growth rate and amplitudes of pixel defects for the H100 sensor. By chosing $q=3$ and appropriate $\tau_{ps}$ as decision thresholds, $n_{ps}(2009)=37$ and $n_{ps}(2013)=38$ candidates for partially-stuck pixels were found in 2009 and 2013 respectively (see fig. \ref{fig:defectPersistence}). Because there where $n_{match}=4$ matching pixels, the correction factor is set to $\gamma=0.1081$. Using these values, a estimated growth rate $\lambda_{ps}=0.129$ can be determined. The growth rates are measured in number of defects per Megapixel per year. The retrieved values (refer table \ref{table:parameters}) correspond with the findings of other researchers, refer \cite{defectDetection, leung}. Dudas suggests in \cite{inFieldDefects} that real stuck pixels are never detected in field, because they are easy to detect at fabrication time and get corrected or may correspond to partially stuck pixels with extremely high offset. However, we modelled actual stuck pixels at a moderate growth rate (refer table. \ref{table:tests}) to investigate what happens if stuck pixels should occur. Furthermore, we modelled other sensors with growth rates retrieved from literature and pushed the aging parameters to mutiples of the real values. To get the highest possible impact, the largest growth rates for the specific sensor were taken. A summary of all used parameters in this simulation is given in table \ref{table:parameters}.

 % TODO: Proof of correctness by probability

 \bgroup
\def\arraystretch{1.3}%  1 is the default, change whatever you need
 \begin{table} [h]
 \begin{center}
  \begin{tabular}{|c | c c c|}
  \hline 
   \textbf{Parameters} & h100  & APS \cite{leung} & CCD \cite{leung} \\
  \hline 
  $\lambda_{ps} [\frac{\text{defects}}{\text{year} \cdot 10^6 \text{pixels}}]$  & 0.129 &  0.743 & 0.569 \\
  $\lambda_s$ 	&  0  & 0 & 0 \\
  $a_s$		&  255  & 255 & 255 \\
  $a_{ps}$	&  3  & ? & ? \\
  \hline  
  \end{tabular}

  \vspace{1mm}
  \hfill \tiny { $1MP := 10^6 pixels$}
  \end{center}
    \vspace{-4mm}
  \label{table:parameters}
  \caption{Simulation parameters. }
\end{table}

\egroup

  Based on these parameters, a number of virtual sensors are defined in table \ref{table:tests}, where sensor A corresponds to the H100. They are designed in a way that all possible combinations of partially-stuck and stuck pixels are covered. Sensors F,G and H show amplitudes and growth rates which are very unlikely to be observed in practice, but should demonstrate the influence of heavy aging effects. 
 
 \begin{table}[h]  
  \begin{tabular}{c | c c c }
  Sensor & $\lambda_{ps}$ & $\lambda_{s}$ & $a_{ps}$  \\
  \hline
  A	&	$\lambda_{h100}$ & 0 & $a_{ps_{h100}}$ \\
  B & $\lambda_{h100}$ & $\lambda_{APS}$ & $a_{ps_{h100}}$ \\
  C & $\lambda_{APS}$ & 0 & $a_{ps_{h100}}$    \\
  D & $\lambda_{CCD}$ & 0 & $a_{ps_{h100}}$   \\
  E & 0 & $\lambda_{APS}$ & -- \\
  F & $ 4 \lambda_{h100}$ & 0 & $ 2 a_{ps_{h100}}$ \\
  G & $ 4 \lambda_{h100}$ & 0 & 100 \\
  H & $ 8 \lambda_{h100}$ &  $ 5 \lambda_{APS}$ & 100

  \end{tabular}
    \label{table:tests}
    \vspace{3mm}
    \caption{Virtual sensors for simulation}
 \end{table}
  
  For each of these sensor models, an aged data set based on the IITD database \cite{iitd} (TIFF, N=2240) over a time span of 96 years is calculated with a step width $\Delta t=8 \text{years}$. This is likely to cover sensor aging over a human being's entire lifetime. The impact of sensor aging is determined by evaluation of the Equal Error Rate EER (also known as Crossover Error Rate). In terms of this paper the EER is calculated by considering the left and right eye of a subject as seperate classes. By the structure of the database (using crossover evaluation), 8940 genuine and 5006400 impostor matches are the base for computing the EER.
  
  Sensor A, which is a model of a real iris scanner, has been tested with all six implementations iris-signature algorithms of the USIT Framework to evaluate each algorithm's vulnerability to sensor aging. For all other virtual sensors, the algorithms of Ma \emph{et al} \cite{Ma} and Monro \emph{et al} \cite{Monro} were used. The segmentation was carried out by Weighted adaptive Hough and ellipsopolar transforms WAHET \cite{wahet}. 
 
 \section{Results}
 \label{results}
 For all six iris signature algorithms no tendency in accuracy change due to sensor aging is observed. This is concluded from investigating the EER on sensor A (refer fig. \ref{fig:sensor1}). There is, however, a significant variation in EER at the sample points for some algorithms. Thus defects caused by sensor aging indeed influence the retrieved iris signatures. Especially for the LogGabor-1D method  \cite{lg}, a high variation between sample points is observed. This indicates that this method is sensitive towards sensor aging. The algorithm of Ko \emph{et al} \cite{ko} and the context based method \cite{cb} tend to be robust.
 
 \begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{img/sensor1.png}
  \caption{EER using Sensor A and WAHET segmentation }
  \label{fig:sensor1}
\end{figure}
 
 
 \subsection{Limitation of the results}
 \begin{itemize}
  \item Only one sensor tested (probably not representative)
  \item In-Camera fixing of sensor defects neglected (might influence development rate, but not so important, because also tested with multiples of the original rate)
  \item unsure whether noise reduction on in iris sensors
  \item But proved in JLEUNG that was off... so these rates probably representative
  \item segmentation or iris code?
 \end{itemize}
 
 
 \section{Conclusion}
 \label{conclusion}
 We used a simulation to embed aging-related defects onto a sensors output. Practical relevance of the simulation has been established by retrieving simulation parameters from data, which has been captured by an iris scanner in a 4 years' difference. To retrieve these parameters, a method was proposed in section \ref{hotPixelRate}. By using these parameters and similar ones from related work, an experiment has been carried out. In this experiment the impact of sensor-aging on the accuracy of iris recognition systems was investigated.
 
 Interpreting the results, we can say that the LogGabor-1D method is vulnerable to aging-related defects.
 
 
 TODO
 \begin{itemize}
  \item No influence of sensor aging found per se.
  \item Backs up the guys who claim that iris texture aging is really relevant and CAN be retrieved by observing influence on recognition rate
  \item TODO: Discuss conclusion with Mr. Uhl 
 \end{itemize}

 \section{Future work}
 \begin{itemize}
  \item Detect hot/stuck pixels by laboratory measurements. Compare to the observed method
  \item Also no true stuck pixel http://euler.ecs.umass.edu/research/ctkk-spie-2013.pdf
 \end{itemize}


% ------------------------ Reference section

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

% TODO: Table referencing does not work!!
% TODO: Figure 2 enhance

\end{document}
